{
    "type": "feature",
    "category": "Amazon Bedrock",
    "contributor": "",
    "description": "Amazon Bedrock Batch Inference/ Model Invocation is a feature which allows customers to asynchronously run inference on a large set of records/files stored in S3."
}
